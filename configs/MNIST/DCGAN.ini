
[HYPERPARAMS]
gen_optimizer = Adam
disc_optimizer = SGD
batch_size = 64
lr = 2e-4
beta1 = 0.5
epochs = 200
loss = BCE

latent_dim = 100
encode_blocks = 5
channel_increase_factor = 2
conv_blocks_per_decrease = 8
initial_upsample_size = 2
skip_connections = yes

base_channels = 16

[DISC_PARAMS]
encode_blocks = 3
conv_blocks_per_decrease = 4



[GAN_HACKS]
noisy_labels = no
input_noise = no
flip_prob = 0.9
noise_factor = 0.1

[TRAINING]
log_every_dataset_chunk = 5
visdom = true
save_epoch_interval = 10
RGB = no
input_size = 28x28