[HYPERPARAMS]
optimizer = Adam
batch_size = 16
lr = 1e-4
epochs = 5
loss = L1
learn_loss_weights = no
IMG_loss_weight = -1
VAE_loss_weight = 3
base_channels = 32
conv_blocks_per_decrease = 4
channel_increase_factor = 2
encode_blocks = 4
latent_dim = 256
initial_upsample_size = 11
skip_connections = yes
auxillary = no

[TRAINING]
log_every_dataset_chunk = 100
save_epoch_interval = 1
visdom = yes
RGB = yes
input_size = 218x178