# Playground project for generative models in PyTorch
In this project I want to implement and try several approaches on generating artificial data from scratch. 
# About data
As these are all Machine Learning models they learn from given data. We are using two different datasets until now. [MNIST](http://yann.lecun.com/exdb/mnist/) and [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). However, it is straightforward to extend implementation to other datasets.
# 1. Autoencoders

<details>
    
 
 <summary><b>Architecture details</b></summary><br/>
  
Autoencoder architecture is fully described by a set of parameters:
    - base_channels: Number of channels after first convolution
    - conv_blocks_per_decrease: Convolutions in each downsizing module
    - channel_increase_factor: Factor by which channels increase after each downsizing module
    - encode_factor: Number of downsizing modules
    - latent_dim: Dimension of encoding vector
    - initial_upsample_size: Start resolution in decoder
    - skip_connections: Use ResNet like skip connections in downsizing modules
    - auxillary: Allow encoder to also learn class labels (makes training easier)
For a more exact description see [configs folder](configs/README.md)
    
A model summary can be retrieved by running `python -m models.Autoencoder -h`. Note: parameters in summary are currently hardcoded.
    
 </details>


<details>
 <summary><b>Convolutional model with linear hidden dimension</b></summary><br/>

    
Autoencoder, that encodes to a n-dimensional linear feature vector. n is dependent on architecture parameters. Standard is 128.
    
<br/>
<b> Reconstructions results for standard Autoencoder (128 dimensions) </b> <br/>

| ![Linear autoencoder result](result_figures/AE_MNIST_reconstruction.png) | 
|:--:|
|MNIST|
    
<!---
| ![Linear autoencoder result](result_figures/AE_MNIST_reconstruction.png) | ![Linear autoencoder result](result_figures/AE_linear_CelebA_reconstruction.png) |
|:--:|:--:|
|MNIST|CelebA|
--->

<!--- Encoding visualized in hidden space \
![Linear autoencoder hidden space](result_figures/2d_encoding_AE_linear.png) --->
#### t-SNE representation of hidden space
To see how well the model is seperating classes, we sample from the test set and visualize their hidden represention using t-SNE. We use MNIST as we have class labels. <br/>
![TSNE of hidden representation for linear autoencoder on MNIST](result_figures/tsne_AE_MNIST.png)
 </details>
 </details>

<details>
 <summary><b> Variational Autoencoders (VAE) </b></summary><br/>
  
Variational autoencoders similarily to Autoencoders trying to find a good hidden encoding for reconstruction of input data. However, they encode to a mean and variance, where the minimization of KL-divergence to a standard normal distribution is part of optimization objective. Thus artificial data can be generated by sampling from a standard normal distribution and decode these. <br/>
<b> Reconstruction of given test samples </b> <br/>

| ![Reconstructed samples VAE MNIST](result_figures/VAE_MNIST_reconstruction.png) | 
|:--:|
|MNIST|

<!---
| ![Reconstructed samples VAE MNIST](result_figures/VAE_MNIST_reconstruction.png) | ![Reconstructed samples VAE CelebA](result_figures/VAE_CelebA_reconstruction.png) |
|:--:|:--:|
|MNIST|CelebA|
--->

<!---
<b> Randomly generated artificial samples </b> <br/>

| ![Artificial MNIST](result_figures/artificial_samples_MNIST.png) | ![Artificial CelebA](result_figures/artificial_samples_CelebA.png) |
|:--:|:--:|
--->

<b> Reconstructed samples from linear grid in two dimensions </b> <br/>
![VAE generated samples MNIST](result_figures/VAE_generation.png) <br/>
</details>
</details>

<!--- Visualization of encoding of mean values in hidden 2d space. Note how it is much more centered around zero. \
![VAE encoding](result_figures/2d_encoding_VAE.png) --->

# 2. Generative Adverserial Networks (GANs)
<details>
 <summary><b> Vanilla GAN </b></summary><br/>
  
  Original GANs (Goodfellow et al) that are based upon linear layers in generator and discriminator.
  ![MNIST_Vanilla_result](result_figures/VanillaGAN_MNIST_2020-01-14_18:49.png)
  
</details>

<details>
 <summary><b> DC GAN </b></summary><br/>
  
  Concept of GANs that utilize convolutional layers in generator and discriminator.
  ![MNIST_DCGAN_result](result_figures/DCGAN_MNIST_2020-01-14_20:50.png)
  
</details>

<details>
 <summary><b> Auxillary GAN </b></summary><br/>
  
  DC GAN but labels of dataset are used as generator input and discriminator output.
  ![MNIST_AUX_DCGAN_result](result_figures/DCGAN_MNIST_2020-01-16_12:36.png)
</details>
